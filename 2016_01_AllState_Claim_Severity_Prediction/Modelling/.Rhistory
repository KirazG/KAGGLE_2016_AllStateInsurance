drfModel2 <- h2o.randomForest(x = impAttribs, y = DepAttrib, training_frame = AllStateTrain.hex, model_id = "DRF_MODEL_02", validation_frame = AllStateTest.hex, ntrees = 75, max_depth = 20, seed = 2016, nfolds = 10)
h2o.mae(object = drfModel1, train = TRUE, valid = TRUE)
# Rebuilding the DRF with only important attributes - 10-fold Cross Validation
drfModel2 <- h2o.randomForest(x = impAttribs, y = DepAttrib, training_frame = AllStateTrain.hex, model_id = "DRF_MODEL_02", validation_frame = AllStateTest.hex, ntrees = 75, max_depth = 20, seed = 2016, nfolds = 10)
# Rebuilding the DRF with only important attributes - 10-fold Cross Validation
drfModel2 <- h2o.randomForest(x = impAttribs, y = DepAttrib, training_frame = AllStateTrain.hex, model_id = "DRF_MODEL_02", ntrees = 75, max_depth = 20, seed = 2016, nfolds = 10)
?h2o.randomForest
drfModel2 <- h2o.randomForest(x = impAttribs, y = DepAttrib, training_frame = AllStateTrain.hex, model_id = "DRF_MODEL_02", ntrees = 50, max_depth = 20, seed = 2016, nfolds = 10, stopping_rounds = 2, stopping_metric = "MSE", stopping_tolerance = 1e-3, score_tree_interval = 50)
drfModel2
drfModel2@model_id
drfModel2@model
drfModel2@model$cross_validation_models
M <- drfModel2@model$cross_validation_models[[DRF_MODEL_02_cv_10]]
M <- drfModel2@model$cross_validation_models[[2]]
<
M
h2o.mae(object = drfModel2, train = TRUE, valid = TRUE)
h2o.mae(object = drfModel2, train = TRUE)
h2o.gbm()
?h2o.gbm
GBM2 <- h2o.gbm(x = impAttribs, y = DepAttrib, training_frame = ModTrain.hex, model_id = "GBM_MODEL_01", validation_frame = ModTest.hex, ntrees = 100, seed = 2016, distribution = "gaussian", max_depth = 10, stopping_rounds = 3, stopping_metric = "MSE")
GBM2
h2o.mae(object = GBM2, train = TRUE, valid = TRUE)
h2o.varimp_plot(model = GBM2)
# Generate Predictions
predDRF1 = h2o.predict(object = GBM2, newdata = AllStateTest.hex)
dfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))
dfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))
names(dfDRF1) = c("id", "loss")
write.csv(x = dfDRF1, file = "H2O_DRF_02.csv", row.names = FALSE)
write.csv(x = dfDRF1, file = "H2O_GBM_02.csv", row.names = FALSE)
GBM2 <- h2o.gbm(x = impAttribs,
y = DepAttrib,
training_frame = ModTrain.hex,
model_id = "GBM_MODEL_02",
validation_frame = ModTest.hex,
ntrees = 150,
seed = 2016,
distribution = "gaussian",
max_depth = 7,
stopping_rounds = 3,
stopping_metric = "MSE")
h2o.mae(object = GBM2, train = TRUE, valid = TRUE)
h2o.varimp_plot(model = GBM2)
# Generate Predictions
predDRF1 = h2o.predict(object = GBM2, newdata = AllStateTest.hex)
dfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))
dfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))
names(dfDRF1) = c("id", "loss")
write.csv(x = dfDRF1, file = "H2O_GBM_03.csv", row.names = FALSE)
GBM2 <- h2o.gbm(x = impAttribs,
y = DepAttrib,
training_frame = ModTrain.hex,
model_id = "GBM_MODEL_02",
validation_frame = ModTest.hex,
ntrees = 250,
seed = 2016,
distribution = "gaussian",
max_depth = 5,
stopping_rounds = 5,
stopping_metric = "MSE")
h2o.mae(object = GBM2, train = TRUE, valid = TRUE)
GBM2 <- h2o.gbm(x = impAttribs,
y = DepAttrib,
training_frame = ModTrain.hex,
model_id = "GBM_MODEL_02",
validation_frame = ModTest.hex,
ntrees = 350,
seed = 2016,
distribution = "gaussian",
max_depth = 5,
stopping_rounds = 3,
stopping_metric = "MSE")
h2o.mae(object = GBM2, train = TRUE, valid = TRUE)
predDRF1 = h2o.predict(object = GBM2, newdata = AllStateTest.hex)
dfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))
names(dfDRF1) = c("id", "loss")
write.csv(x = dfDRF1, file = "H2O_GBM_03.csv", row.names = FALSE)
write.csv(x = dfDRF1, file = "H2O_GBM_04.csv", row.names = FALSE)
h2o.saveModel(object = GBM2, path = getwd())
impAttribs
library(h2o)
# Initialize H2O
h2o.init(nthreads = -1, max_mem_size = "1G")
?h2o.glm
?h2o.grid
impAttribs
paste0(impAttrib)
paste0(impAttribs, ",")
paste0(impAttribs, collapse = ",")
impAttribs
rm(list = ls(all.names = TRUE))
rm(list = ls(all.names = TRUE))
library(h2o)
# Initialize H2O
h2o.init(nthreads = -1, max_mem_size = "1G")
# Cleanup H2O Enviroment
h2o.removeAll()
# Read Train & Test into H2O
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
AllStateTrain.hex$id = NULL
AllStateTest.hex$id = NULL
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 2016)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
DepAttrib = "loss"
# IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
# Using Only Top 23 attributes selected from DRF [This was run on 13-10-2016]
IndAttrib = c("cat116","cat80","cat79","cat112","cat113","cat101","cat87","cat100","cat57","cat110","cat115","cont2","cat12","cat81","cont7","cat105","cat114","cat107","cat103","cont12","cat104","cat111","cat106")
################################################################################
##### GLM with Lasso (L1), Ridge (L2) & ElasticNet @ Alpha = 0.5           #####
################################################################################
glmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Ridge_01", family = "gaussian", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex, remove_collinear_columns = TRUE)
glmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_ElasticNet_01", family = "gaussian", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex, remove_collinear_columns = TRUE)
glmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Lasso_01", family = "gaussian", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex, remove_collinear_columns = TRUE)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
### Generate Predictions
predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
glmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Ridge_01", family = "gaussian", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex)
#, remove_collinear_columns = TRUE)
glmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_ElasticNet_01", family = "gaussian", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex)
#, remove_collinear_columns = TRUE)
glmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Lasso_01", family = "gaussian", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex)
#, remove_collinear_columns = TRUE)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
1/2
1/4
1/8
1/16
1/32
1/64
1/128
1/256
1/5
1/25
1/125
1/625
Lamdas = c(1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001)
Alpha = seq(0.5,0.95,0.05)
HParam = list(alpha = Alpha, lambda = Lamdas)
glmGridSearch2 = h2o.grid(algorithm = "glm",
grid_id = "GLMGrid_02",
hyper_params = HParam,
x = IndAttrib,
Lamdas = c(1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001)
Alpha = seq(0.5,0.95,0.05)
HParam = list(alpha = Alpha, lambda = Lamdas)
glmGridSearch2 = h2o.grid(algorithm = "glm",
grid_id = "GLMGrid_02",
hyper_params = HParam,
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
validation_frame = ModTest.hex,
family = "gaussian",
is_supervised = TRUE)
glmGridModels2 = lapply(glmGridSearch2@model_ids, function(x){h2o.getModel(x)})
glmGridModels2 = lapply(glmGridSearch2@model_ids, function(x){h2o.getModel(x)})
MAE2 = unlist(lapply(glmGridModels2, function(x) {h2o.mae(object = x)}))
BestGridModel2 = glmGridModels2[[which.min(MAE2)]]
### Generate Predictions From The Best Grid Model & Write To CSV
BestGridModel2
nrow(AllStateTrain.hex)
AllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss >= 50000, ]
nrow(AllStateTrain.hex)
AllStateTrain.hex$loss
AllStateTrain.hex$loss[1:11,]
T <- AllStateTrain.hex$loss
T
View(as.data.frame(T))
# Read Train & Test into H2O
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
AllStateTrain.hex$id = NULL
AllStateTest.hex$id = NULL
# Selecting Only Subset of Training Data - Potentially Exlcuding Outliers
nrow(AllStateTrain.hex)
nrow(AllStateTrain.hex[AllStateTrain.hex$loss <= 50000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 50000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 40000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 30000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 20000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 40000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 35000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 30000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 25000, ])
159/1883
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 20000, ])
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 20000, ])/1883
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 15000, ])/1883
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 10000, ])/1883
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 20000, ])/1883
nrow(AllStateTrain.hex[AllStateTrain.hex$loss >= 25000, ])/1883
nrow(AllStateTrain.hex)
AllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss <= 25000, ]
nrow(AllStateTrain.hex)
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 2016)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
DepAttrib = "loss"
DepAttrib = "loss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
glmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Ridge_01", family = "gaussian", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex)
glmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_ElasticNet_01", family = "gaussian", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex)
glmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Lasso_01", family = "gaussian", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
### Generate Predictions
predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
dfRidge = as.data.frame(h2o.cbind(AllStateTest.hex$id, predRidge))
names(dfRidge) = c("id", "loss")
dfEnet = as.data.frame(h2o.cbind(AllStateTest.hex$id, predENet))
names(dfEnet) = c("id", "loss")
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
### Generate Predictions
predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
### Convert all predictions to R DataFrames
dfRidge = as.data.frame(h2o.cbind(AllStateTest.hex$id, predRidge))
names(dfRidge) = c("id", "loss")
dfEnet = as.data.frame(h2o.cbind(AllStateTest.hex$id, predENet))
names(dfEnet) = c("id", "loss")
dfLasso = as.data.frame(h2o.cbind(AllStateTest.hex$id, predLasso))
names(dfLasso) = c("id", "loss")
### Write all predictions into a CSV
write.csv(x = dfRidge, file = "../Predictions/2016_10_13/H2O_Ridge.csv", row.names = FALSE)
write.csv(x = dfEnet, file = "../Predictions/2016_10_13/H2O_Enet.csv", row.names = FALSE)
write.csv(x = dfLasso, file = "../Predictions/2016_10_13/H2O_Lasso.csv", row.names = FALSE)
Lamdas = c(0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001,0.000000001)
Alpha = seq(0.5,0.95,0.05)
HParam = list(alpha = Alpha, lambda = Lamdas)
glmGridSearch2 = h2o.grid(algorithm = "glm",
grid_id = "GLMGrid_02",
hyper_params = HParam,
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
validation_frame = ModTest.hex,
family = "gaussian",
is_supervised = TRUE)
hyper_params = HParam,
glmGridModels2 = lapply(glmGridSearch2@model_ids, function(x){h2o.getModel(x)})
MAE2 = unlist(lapply(glmGridModels2, function(x) {h2o.mae(object = x)}))
BestGridModel2 = glmGridModels2[[which.min(MAE2)]]
BestGridModel2
nrow(AllStateTrain.hex)
#HypParams = list(ntrees = c(50,75,100), max_depth = c(18,20,22))
HypParams = list(ntrees = c(100), max_depth = c(22,25))
drfGridSearch1 = h2o.grid(algorithm = "randomForest",
grid_id = "DRF_GRID_01",
hyper_params = HypParams,
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
validation_frame = ModTest.hex,
is_supervised = TRUE,
seed = 2016)
# BEST MODEL: ntree = 100 | max_depth = 22 | seed = 100 | features = ALL
drfGrid1 <- h2o.getGrid(grid_id = "DRF_GRID_01", sort_by = "mse", decreasing = FALSE)
print(drfGrid1)
source('C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/Modelling/AllStateInsurance_Modelling_GLM_01.R', echo=TRUE)
dfTemp <- read.csv(file = "../train.csv")
hist(dfTemp$loss)
hist(log(dfTemp$loss))
hist(log(dfTemp$loss))
hist(log10(dfTemp$loss))
install.packages("xgboost")
rm(list = ls(all.names = TRUE))
library(h2o)
# Initialize H2O
h2o.init(nthreads = -1, max_mem_size = "1G")
# Cleanup H2O Enviroment
h2o.removeAll()
# Read Train & Test into H2O
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
AllStateTrain.hex$id = NULL
# Selecting Only Subset of Training Data - Potentially Exlcuding Outliers
nrow(AllStateTrain.hex)
AllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss <= 52000, ]
nrow(AllStateTrain.hex)
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 2016)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
DepAttrib = "loss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
glmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Ridge_01", family = "gaussian", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex)
glmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_ElasticNet_01", family = "gaussian", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex)
glmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Lasso_01", family = "gaussian", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
### Generate Predictions
predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
### NOT allowing Lasso & Ridge Regualarization To Be Included In GRID SEARCH
### Narrowed down the values for "lambdas" and expanded the values for Alpha
Lamdas = c(0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001,0.000000001)
Alpha = seq(0.5,0.95,0.05)
HParam = list(alpha = Alpha, lambda = Lamdas)
glmGridSearch2 = h2o.grid(algorithm = "glm",
grid_id = "GLMGrid_02",
hyper_params = HParam,
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
validation_frame = ModTest.hex,
family = "gaussian",
is_supervised = TRUE)
glmGridModels2 = lapply(glmGridSearch2@model_ids, function(x){h2o.getModel(x)})
MAE2 = unlist(lapply(glmGridModels2, function(x) {h2o.mae(object = x)}))
BestGridModel2 = glmGridModels2[[which.min(MAE2)]]
BestGridModel2
?h2o.randomForest
BestGridModel2
HypParams = list(ntrees = c(100,125), max_depth = c(20))
drfGridSearch1 = h2o.grid(algorithm = "randomForest",
grid_id = "DRF_GRID_01",
hyper_params = HypParams,
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
validation_frame = ModTest.hex,
col_sample_rate_per_tree = 0.5,
is_supervised = TRUE,
seed = 2016)
# BEST MODEL: ntree = 100 | max_depth = 22 | seed = 100 | features = ALL
drfGrid1 <- h2o.getGrid(grid_id = "DRF_GRID_01", sort_by = "mse", decreasing = FALSE)
print(drfGrid1)
drfBestGridModel1 <- h2o.getModel(drfGrid1@model_ids[[1]])
h2o.mae(object = drfBestGridModel1, train = TRUE, valid = TRUE)
library(h2o)
# Initialize H2O
h2o.init(nthreads = -1, max_mem_size = "1G")
# Cleanup H2O Enviroment
#h2o.removeAll()
# Read Train & Test into H2O
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
AllStateTrain.hex$id = NULL
ncol(AllStateTrain.hex)
h2o.log(100)
h2o.log(4)
exp(4.6)
h2o.log(0.67)
h2o.log(1)
h2o.log(121000)
AllStateTrain.hex$LogLoss = h2o.log(AllStateTrain.hex$loss)
ncol(AllStateTrain.hex)
str(AllStateTrain.hex)
summary(AllStateTrain.hex)
hist(AllStateTrain.hex$loss)
hist(AllStateTrain.hex$LogLoss)
hist(as.data.fram(AllStateTrain.hex$LogLoss))
hist(as.data.frame(AllStateTrain.hex$LogLoss))
str(AllStateTrain.hex4loss)
str(AllStateTrain.hex$loss)
hist(1:10)
hist(1:100)
hist(as.numeric(AllStateTrain.hex$loss))
hist(as.numeric(as.data.frame(AllStateTrain.hex)$loss))
hist(as.numeric(as.data.frame(AllStateTrain.hex)$LogLoss))
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
AllStateTrain.hex$id = NULL
# DATA TRANSFORMATION: Converting Loss varibale into Log10(loss) to make the Right Skewed distribution Normal
ncol(AllStateTrain.hex)
AllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss >= 1, ]
AllStateTrain.hex$LogLoss = h2o.log(AllStateTrain.hex$loss)
# DepAttrib = "loss"
DepAttrib = "LogLoss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
glmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Ridge_01", family = "gaussian", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex)
glmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_ElasticNet_01", family = "gaussian", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex)
glmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Lasso_01", family = "gaussian", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
### Generate Predictions
predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
predENet
AllStateTrain.hex$LogLoss
glmRidge
ncol(ModTrain.hex)
ncol(ModTest.hex)
ModTest.hex[ ,c(130,131)]
# DATA TRANSFORMATION: Converting Loss varibale into Log10(loss) to make the Right Skewed distribution Normal
ncol(AllStateTrain.hex)
AllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss >= 1, ]
AllStateTrain.hex$LogLoss = h2o.log(AllStateTrain.hex$loss)
ncol(AllStateTrain.hex)
ModTest.hex[ ,c(131,132)]
str(ModTest.hex)
summary(ModTest.hex)
summary(ModTrain.hex)
AllStateTrain.hex$LogLoss
ModTest.hex$LogLoss
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 2016)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
# DepAttrib = "loss"
DepAttrib = "LogLoss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
# Using Only Top 23 attributes selected from DRF [This was run on 13-10-2016]
#IndAttrib = c("cat116","cat80","cat79","cat112","cat113","cat101","cat87","cat100","cat57","cat110","cat115","cont2","cat12","cat81","cont7","cat105","cat114","cat107","cat103","cont12","cat104","cat111","cat106")
################################################################################
##### GLM with Lasso (L1), Ridge (L2) & ElasticNet @ Alpha = 0.5           #####
################################################################################
ModTest.hex
ncol(ModTest.hex)
ncol(ModTrain.hex)
glmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Ridge_01", family = "gaussian", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex)
glmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_ElasticNet_01", family = "gaussian", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex)
glmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = "AllState_Lasso_01", family = "gaussian", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
h2o.exp(0)
h2o.exp(1)
h2o.exp(0.2727)
predRidge
predRidge = h2o.predict(object = glmRidge, newdata = ModTest.hex)
predRidge
predRidge = h2o.predict(object = glmRidge, newdata = ModTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predENet
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
predLasso
CALC_MAE <- function(Actuals, Predicted)
{
ifelse((length(Actuals) != 0 & length(Predicted) != 0 & (length(Actuals) == length(Predicted))), return(abs(Actuals - Predicted)/length(Actuals)), return(NaN))
}
CALC_MAE(1:10,1:10)
CALC_MAE <- function(Actuals, Predicted)
{
ifelse((length(Actuals) != 0 & length(Predicted) != 0 & (length(Actuals) == length(Predicted))), return(sum(abs(Actuals - Predicted))/length(Actuals)), return(NaN))
}
CALC_MAE(1:10,1:10)
CALC_MAE(1:10,2:11)
CALC_MAE(1:10,2:12)
CALC_MAE()
predRidge = h2o.predict(object = glmRidge, newdata = ModTest.hex)
predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)
predENet
predRidge
predLasso
CALC_MAE(AllStateTest.hex$loss, predRidge)
### MAE calculation
h2o.mae(object = glmRidge, train = TRUE, valid = TRUE)
h2o.mae(object = glmENet, train = TRUE, valid = TRUE)
h2o.mae(object = glmLasso, train = TRUE, valid = TRUE)
AllStateTest.hex$loss-predRidge
ModTest.hex$loss-predRidge
CALC_MAE(ModTest.hex$loss,predRidge)
sum(abs(ModTest.hex$loss-predRidge))
length(predRidge)
nrow(predRidge)
CALC_MAE <- function(Actuals, Predicted)
{
ifelse((length(Actuals) != 0 & length(Predicted) != 0 & (length(Actuals) == length(Predicted))), return(sum(abs(Actuals - Predicted))/nrow(Actuals)), return(NaN))
}
sum(abs(ModTest.hex$loss-predRidge))/nrow(predRidge)
CALC_MAE(ModTest.hex$loss, predRidge)
CALC_MAE(ModTest.hex$loss, predRidge)
CALC_MAE(ModTest.hex$loss, predENet)
CALC_MAE(ModTest.hex$loss, predLasso)
CALC_MAE(ModTest.hex$loss, predRidge)
CALC_MAE(ModTest.hex$loss, predENet)
nrow(predRidge)
nrow(predENet)
predRidge = h2o.predict(object = glmRidge, newdata = ModTest.hex)
predENet = h2o.predict(object = glmENet, newdata = ModTest.hex)
predLasso = h2o.predict(object = glmLasso, newdata = ModTest.hex)
CALC_MAE(ModTest.hex$loss, predRidge)
CALC_MAE(ModTest.hex$loss, predENet)
CALC_MAE(ModTest.hex$loss, predLasso)
sum(predRidge - predENet)
sum(predRidge - predLasso)
library(Boruta)
