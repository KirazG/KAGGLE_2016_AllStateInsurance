1+log(4000)
log(e)
log2(4000)
log2(4000)
2^11.96578
1+log2(4000)
install.packages(pkgs = c("readxl", "gdata", "XLConnect"), dependencies = TRUE )
install.packages(pkgs = c("readr", "data.table"), dependencies = TRUE )
install.packages(pkgs = c("lubridate"), dependencies = TRUE )
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# Next, we download packages that H2O depends on.
pkgs <- c("methods","statmod","stats","graphics","RCurl","jsonlite","tools","utils")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R")))
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R")))
library(h2o)
localH2O = h2o.init(nthreads=-1)
# Finally, let's run a demo to see H2O at work.
demo(h2o.kmeans)
h2o.clusterInfo()
h2o.clusterIsUp()
h2o.cluster_sizes()
h2o.clusterStatus()
h2o.clusterInfo()
h2o.shutdown()
h2o.clusterIsUp()
q()
version()
info()
q()
install.packages("dplyr")
library(dplyr)
dfVars = read.csv(file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv")
setwd("D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/Modelling")
dfVars = read.csv(file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv")
View(dfVars)
dfGroup <- group_by(.data = dfVars, variable) %>% summarise(AvgPercent = mean())
dfGroup <- group_by(.data = dfVars, variable) %>% summarise(AvgPercent = mean(percentage))
View(dfGroup)
dfGroup <- group_by(.data = dfVars, variable) %>% mutate(AvgPercent = mean(percentage))
dfGroup <- group_by(.data = dfVars, variable) %>% mutate(AvgPercent = mean(percentage)) %>% arrange(AvgPercent)
View(dfGroup)
?arrange
dfGroup <- group_by(.data = dfVars, variable) %>% mutate(AvgPercent = mean(percentage)) %>% arrange(desc(AvgPercent))
?arrange
View(dfGroup)
dfGroup <- group_by(.data = dfVars, variable) %>% mutate(AvgPercent = mean(percentage)) %>% arrange(desc(AvgPercent)) %>% select(variable, AvgPercent) %>% distinct(.keep_all = TRUE)
write.csv(x = dfGroup, file = "GBM_IMP_VARIABLES.csv", row.names = FALSE)
# Cleanup the environment and load libraries
rm(list = ls(all.names = TRUE))
library(h2o)
# Initialize H2O :: DELL_LAPTOP
#h2o.init(nthreads = -1, min_mem_size = "6G")
# Initialize H2O :: LENOVO_AIO
h2o.init(nthreads = -1, min_mem_size = "3500M")
# Read Train & Test into H2O - DELL_LAPTOP
#AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
#AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
# Read Train & Test into H2O - LENOVO_AIO
AllStateTrain.hex = h2o.uploadFile(path = "D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
# Transform "loss" variable to Log(loss)
AllStateTrain.hex$loss = h2o.log(AllStateTrain.hex$loss)
# No loss variable in AllStateTest.hex
# Save and remove id column from Train & Test dataset
TrainId = AllStateTrain.hex$id
TestId = AllStateTest.hex$id
AllStateTrain.hex$id = NULL
AllStateTest.hex$id = NULL
# Variable names
vFactors = paste0("cat", 1:116)
vNumbers = paste0("cont", 1:14)
# Perform PCA on numeric data >> Remove original attributes >> Select & attach important components
PCA = h2o.prcomp(training_frame = AllStateTrain.hex, x = vNumbers, k = length(vNumbers), model_id = "PCA_01", transform = "STANDARDIZE", seed = 1)
# Remove Continuous variable and add PCA Score - Train data frame
AllStateTrainPCA.hex = h2o.assign(data = h2o.predict(object = PCA, newdata = AllStateTrain.hex), key = "AllStateTrainPCA.hex")
AllStateTrain.hex[ ,vNumbers] = NULL
AllStateTrain.hex = h2o.cbind(AllStateTrain.hex, AllStateTrainPCA.hex[ ,1:12])
# Remove Continuous variable and add PCA Score - Test Data Frame
AllStateTestPCA.hex = h2o.assign(data = h2o.predict(object = PCA, newdata = AllStateTest.hex), key = "AllStateTestPCA.hex")
AllStateTest.hex[ ,vNumbers] = NULL
AllStateTest.hex = h2o.cbind(AllStateTest.hex, AllStateTestPCA.hex[ ,1:12])
# Split Training Data into Train & Validation set
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 1)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
# Attribute split for further modelling.
DepAttrib = "loss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
HyperParam = list(learn_rate = 0.02, ntrees = 600, max_depth = 10)
KaggelModel1 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "KAGGLE_MODEL_1",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
HyperParam = list(learn_rate = 0.02, ntrees = 600, max_depth = 10)
KaggelModel1 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "KAGGLE_MODEL_1",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
TopModel = h2o.getModel(model_id = KaggelModel1@model_ids[[1]])
# Generate Predictions
predGBM = h2o.predict(object = TopModel, newdata = AllStateTest.hex)
predGBM = h2o.predict(object = TopModel, newdata = AllStateTest.hex)
predGBM
# Following step is required only for Log(loss) predictions
predGBM = h2o.exp(predGBM)
dfGBMPredictions = as.data.frame(h2o.cbind(TestId, predGBM))
names(dfGBMPredictions) = c("id", "loss")
write.csv(x = dfGBMPredictions, file = "H2O_GBM_29102016_01.csv", row.names = FALSE)
### Strata 1: 0.055-0.100
HyperParam = list(learn_rate = seq(0.005,0.040,0.0025),
ntrees = c(1000))
HyperParam
HyperParam = list(learn_rate = seq(0.005,0.040,0.0025),
ntrees = c(1200))
gridLRate5 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "GRID_LEARNRATE_NOANNEAL_6",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
max_depth = 10,
#ntrees = 200,
## smaller learning rate is better
## Due to learning_rate_annealing, we can start with a bigger learning rate
#learn_rate = 0.05,
## learning rate annealing: learning_rate shrinks by 1% after every tree
#learn_rate_annealing = 0.95,
## Early stopping configuration
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
M1 <- gridLRate5@model_ids[[1]]
M1 <- gridLRate5@model_ids[[1]]
M1@
p
M1
M1 <- h2o.getMoel(gridLRate5@model_ids[[1]])
M1 <- h2o.getModel(gridLRate5@model_ids[[1]])
unlist(lapply(lapply(gridLRate5@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
M1@model_id
gridLRate5@model_ids
unlist(gridLRate5@model_ids)
# LIST OF GRIDS FROM WHICH DATA NEEDS TO BE EXTRACTED
GRID_Ids = c("GRID_LEARNRATE_NOANNEAL_2", "GRID_LEARNRATE_NOANNEAL_3", "GRID_LEARNRATE_NOANNEAL_4", "GRID_LEARNRATE_NOANNEAL_5", "GRID_LEARNRATE_NOANNEAL_6")
# EMPTY DATA FRAMES FOR CONSOLIDATING DATA
dfFinal = data.frame()
dfImpVars = data.frame()
for(i in 1:length(GRID_Ids))
{
# OBTAIN GRID AND "THE BEST" MODEL OF THAT GRID
GRID = h2o.getGrid(grid_id = GRID_Ids[i], sort_by = "mse")
TopMod = h2o.getModel(model_id = GRID@model_ids[[1]])
ModelName = unlist(GRID@model_ids)
# EXTRACT MODEL PARAMETERS FOR EACH MODEL IN THE GRID
ntrees = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$ntrees}))
max_depth = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$max_depth}))
learn_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate}))
learn_rate_annealing = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate_annealing}))
col_sample_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$col_sample_rate}))
stopping_rounds = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_rounds}))
stopping_metric = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_metric}))
stopping_tolerance = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_tolerance}))
score_tree_interval  = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$score_tree_interval}))
distribution = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$distribution}))
# EXTRACT IMPORTANT PARAMETERS FOR SCORING ROUND OF EACH MODEL IN THE GRID
Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_deviance"])}))
TrainDev_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_deviance[which.min(y@model$scoring_history[,"validation_deviance"])]}))
ntree_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_deviance"])]}))
Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_mae"])}))
TrainMAE_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_mae[which.min(y@model$scoring_history[,"validation_mae"])]}))
ntree_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_mae"])]}))
MaxTreesBuilt = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
# COMBINE EXTRACTED RESULTS VERTICALLY
df1 = cbind(ModelName, ntrees, max_depth, learn_rate, learn_rate_annealing, col_sample_rate, stopping_rounds, stopping_metric, stopping_tolerance,
score_tree_interval, distribution, Min_Val_Dev, TrainDev_At_Min_Val_Dev, ntree_At_Min_Val_Dev, Min_Val_MAE, TrainMAE_At_Min_Val_MAE,
ntree_At_Min_Val_MAE, MaxTreesBuilt)
# UPDATE FINAL DATA FRAMES: MODEL PARAMETERS + SCORING DATA + IMPORTANT VARIABLS
dfFinal = rbind(dfFinal, as.data.frame(df1))
dfImpVars = rbind(dfImpVars, TopMod@model$variable_importances)
}
# WRITE TO DISK
write.csv(x = dfFinal, file = "GBM_TUNING_PARAMETERS.csv", row.names = FALSE)
write.csv(x = dfImpVars, file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv", row.names = FALSE)
