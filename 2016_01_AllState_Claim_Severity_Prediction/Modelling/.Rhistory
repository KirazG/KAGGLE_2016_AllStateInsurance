## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5,
search_criteria = list(strategy = "RandomDiscrete",
max_runtime_secs = 15000))
h2o.clusterIsUp()
h2o.clusterInfo()
# LIST OF GRIDS FROM WHICH DATA NEEDS TO BE EXTRACTED
#GRID_Ids = c("GRID_LEARNRATE_NOANNEAL_2", "GRID_LEARNRATE_NOANNEAL_3", "GRID_LEARNRATE_NOANNEAL_4", "GRID_LEARNRATE_NOANNEAL_5", "GRID_LEARNRATE_NOANNEAL_6")
GRID_Ids = c("KAGGLE_GRID_3")
# EMPTY DATA FRAMES FOR CONSOLIDATING DATA
dfFinal = data.frame()
dfImpVars = data.frame()
for(i in 1:length(GRID_Ids))
{
# OBTAIN GRID AND "THE BEST" MODEL OF THAT GRID
GRID = h2o.getGrid(grid_id = GRID_Ids[i], sort_by = "mse")
TopMod = h2o.getModel(model_id = GRID@model_ids[[1]])
ModelName = unlist(GRID@model_ids)
# EXTRACT MODEL PARAMETERS FOR EACH MODEL IN THE GRID
ntrees = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$ntrees}))
max_depth = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$max_depth}))
learn_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate}))
learn_rate_annealing = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate_annealing}))
col_sample_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$col_sample_rate}))
stopping_rounds = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_rounds}))
stopping_metric = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_metric}))
stopping_tolerance = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_tolerance}))
score_tree_interval  = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$score_tree_interval}))
distribution = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$distribution}))
# EXTRACT IMPORTANT PARAMETERS FOR SCORING ROUND OF EACH MODEL IN THE GRID
Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_deviance"])}))
TrainDev_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_deviance[which.min(y@model$scoring_history[,"validation_deviance"])]}))
ntree_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_deviance"])]}))
Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_mae"])}))
TrainMAE_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_mae[which.min(y@model$scoring_history[,"validation_mae"])]}))
ntree_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_mae"])]}))
MaxTreesBuilt = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
# COMBINE EXTRACTED RESULTS VERTICALLY
df1 = cbind(ModelName, ntrees, max_depth, learn_rate, learn_rate_annealing, col_sample_rate, stopping_rounds, stopping_metric, stopping_tolerance,
score_tree_interval, distribution, Min_Val_Dev, TrainDev_At_Min_Val_Dev, ntree_At_Min_Val_Dev, Min_Val_MAE, TrainMAE_At_Min_Val_MAE,
ntree_At_Min_Val_MAE, MaxTreesBuilt)
# UPDATE FINAL DATA FRAMES: MODEL PARAMETERS + SCORING DATA + IMPORTANT VARIABLS
dfFinal = rbind(dfFinal, as.data.frame(df1))
dfImpVars = rbind(dfImpVars, TopMod@model$variable_importances)
}
# WRITE TO DISK
write.csv(x = dfFinal, file = "GBM_TUNING_PARAMETERS.csv", row.names = FALSE)
write.csv(x = dfImpVars, file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv", row.names = FALSE)
KaggelGrid4 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "KAGGLE_GRID_4",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5,
search_criteria = list(strategy = "RandomDiscrete",
max_runtime_secs = 15000))
HyperParam
HyperParam = list(learn_rate = 0.02, ntrees = 1200, max_depth = c(4,5,6,7,8,9,10,11,12,13))
KaggelGrid4 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "KAGGLE_GRID_4",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
#HyperParam = list(learn_rate = 0.0125, ntrees = 1500, max_depth = c(9,11,12,13,14,15,16,17,18))
HyperParam = list(learn_rate = 0.02, ntrees = 1200, max_depth = c(4,5,6,7,8,9,10,11,12,13))
KaggelGrid4 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "KAGGLE_GRID_4",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
#search_criteria = list(strategy = "RandomDiscrete",
#                     max_runtime_secs = 15000))
# LIST OF GRIDS FROM WHICH DATA NEEDS TO BE EXTRACTED
#GRID_Ids = c("GRID_LEARNRATE_NOANNEAL_2", "GRID_LEARNRATE_NOANNEAL_3", "GRID_LEARNRATE_NOANNEAL_4", "GRID_LEARNRATE_NOANNEAL_5", "GRID_LEARNRATE_NOANNEAL_6")
GRID_Ids = c("KAGGLE_GRID_4")
# EMPTY DATA FRAMES FOR CONSOLIDATING DATA
dfFinal = data.frame()
dfImpVars = data.frame()
for(i in 1:length(GRID_Ids))
{
# OBTAIN GRID AND "THE BEST" MODEL OF THAT GRID
GRID = h2o.getGrid(grid_id = GRID_Ids[i], sort_by = "mse")
TopMod = h2o.getModel(model_id = GRID@model_ids[[1]])
ModelName = unlist(GRID@model_ids)
# EXTRACT MODEL PARAMETERS FOR EACH MODEL IN THE GRID
ntrees = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$ntrees}))
max_depth = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$max_depth}))
learn_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate}))
learn_rate_annealing = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate_annealing}))
col_sample_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$col_sample_rate}))
stopping_rounds = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_rounds}))
stopping_metric = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_metric}))
stopping_tolerance = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_tolerance}))
score_tree_interval  = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$score_tree_interval}))
distribution = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$distribution}))
# EXTRACT IMPORTANT PARAMETERS FOR SCORING ROUND OF EACH MODEL IN THE GRID
Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_deviance"])}))
TrainDev_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_deviance[which.min(y@model$scoring_history[,"validation_deviance"])]}))
ntree_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_deviance"])]}))
Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_mae"])}))
TrainMAE_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_mae[which.min(y@model$scoring_history[,"validation_mae"])]}))
ntree_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_mae"])]}))
MaxTreesBuilt = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
# COMBINE EXTRACTED RESULTS VERTICALLY
df1 = cbind(ModelName, ntrees, max_depth, learn_rate, learn_rate_annealing, col_sample_rate, stopping_rounds, stopping_metric, stopping_tolerance,
score_tree_interval, distribution, Min_Val_Dev, TrainDev_At_Min_Val_Dev, ntree_At_Min_Val_Dev, Min_Val_MAE, TrainMAE_At_Min_Val_MAE,
ntree_At_Min_Val_MAE, MaxTreesBuilt)
# UPDATE FINAL DATA FRAMES: MODEL PARAMETERS + SCORING DATA + IMPORTANT VARIABLS
dfFinal = rbind(dfFinal, as.data.frame(df1))
dfImpVars = rbind(dfImpVars, TopMod@model$variable_importances)
}
# WRITE TO DISK
write.csv(x = dfFinal, file = "GBM_TUNING_PARAMETERS.csv", row.names = FALSE)
write.csv(x = dfImpVars, file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv", row.names = FALSE)
KaggelModel1@model_ids[[KAGGLE_GRID_4_model_4]]
KaggelGrid4@model_ids[["KAGGLE_GRID_4_model_4"]]
KaggleGrid = h2o.grid("KAGGLE_GRID_4")
KaggleGrid = h2o.getGrid("KAGGLE_GRID_4", sort_by = "mse")
KaggleGrid
TopModel = h2o.getModel(model_id = KaggelModel1@model_ids[[1]])
KaggleGrid = h2o.getGrid("KAGGLE_GRID_4", sort_by = "mse")
KaggleGrid
TopModel = h2o.getModel(model_id = KaggleGrid@model_ids[[1]])
TopModel
# Generate Predictions
predGBM = h2o.predict(object = TopModel, newdata = AllStateTest.hex)
# Following step is required only for Log(loss) predictions
predGBM = h2o.exp(predGBM)
dfGBMPredictions = as.data.frame(h2o.cbind(TestId, predGBM))
names(dfGBMPredictions) = c("id", "loss")
write.csv(x = dfGBMPredictions, file = "H2O_GBM_01112016_01.csv", row.names = FALSE)
TopModel = h2o.getModel(model_id = KaggleGrid@model_ids[[2]])       # MAX_DEPTH = 8
TopModel
# Generate Predictions
predGBM = h2o.predict(object = TopModel, newdata = AllStateTest.hex)
# Following step is required only for Log(loss) predictions
predGBM = h2o.exp(predGBM)
dfGBMPredictions = as.data.frame(h2o.cbind(TestId, predGBM))
names(dfGBMPredictions) = c("id", "loss")
write.csv(x = dfGBMPredictions, file = "H2O_GBM_01112016_02.csv", row.names = FALSE)
?h2o.gbm
## Trying learning rate annealing.
HyperParam = list(learn_rate = 0.02, ntrees = 1200, max_depth = c(7,8), learn_rate_annealing = c(0.999, 0.997, 0.995, 0.99))
HyperParam
HyperParam = list(learn_rate = 0.02, ntrees = 1200, max_depth = c(7,8), learn_rate_annealing = c(0.999, 0.997, 0.995, 0.99))
KaggleGrid5 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "GBM_GRID_LR_ANNEAL_1",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
# LIST OF GRIDS FROM WHICH DATA NEEDS TO BE EXTRACTED
#GRID_Ids = c("GRID_LEARNRATE_NOANNEAL_2", "GRID_LEARNRATE_NOANNEAL_3", "GRID_LEARNRATE_NOANNEAL_4", "GRID_LEARNRATE_NOANNEAL_5", "GRID_LEARNRATE_NOANNEAL_6")
#GRID_Ids = c("KAGGLE_GRID_4")
GRID_Ids = c("GBM_GRID_LR_ANNEAL_1", "KAGGLE_GRID_4")
# EMPTY DATA FRAMES FOR CONSOLIDATING DATA
dfFinal = data.frame()
dfImpVars = data.frame()
for(i in 1:length(GRID_Ids))
{
# OBTAIN GRID AND "THE BEST" MODEL OF THAT GRID
GRID = h2o.getGrid(grid_id = GRID_Ids[i], sort_by = "mse")
TopMod = h2o.getModel(model_id = GRID@model_ids[[1]])
ModelName = unlist(GRID@model_ids)
# EXTRACT MODEL PARAMETERS FOR EACH MODEL IN THE GRID
ntrees = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$ntrees}))
max_depth = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$max_depth}))
learn_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate}))
learn_rate_annealing = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate_annealing}))
col_sample_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$col_sample_rate}))
stopping_rounds = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_rounds}))
stopping_metric = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_metric}))
stopping_tolerance = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_tolerance}))
score_tree_interval  = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$score_tree_interval}))
distribution = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$distribution}))
# EXTRACT IMPORTANT PARAMETERS FOR SCORING ROUND OF EACH MODEL IN THE GRID
Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_deviance"])}))
TrainDev_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_deviance[which.min(y@model$scoring_history[,"validation_deviance"])]}))
ntree_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_deviance"])]}))
Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_mae"])}))
TrainMAE_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_mae[which.min(y@model$scoring_history[,"validation_mae"])]}))
ntree_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_mae"])]}))
MaxTreesBuilt = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
# COMBINE EXTRACTED RESULTS VERTICALLY
df1 = cbind(ModelName, ntrees, max_depth, learn_rate, learn_rate_annealing, col_sample_rate, stopping_rounds, stopping_metric, stopping_tolerance,
score_tree_interval, distribution, Min_Val_Dev, TrainDev_At_Min_Val_Dev, ntree_At_Min_Val_Dev, Min_Val_MAE, TrainMAE_At_Min_Val_MAE,
ntree_At_Min_Val_MAE, MaxTreesBuilt)
# UPDATE FINAL DATA FRAMES: MODEL PARAMETERS + SCORING DATA + IMPORTANT VARIABLS
dfFinal = rbind(dfFinal, as.data.frame(df1))
dfImpVars = rbind(dfImpVars, TopMod@model$variable_importances)
}
# WRITE TO DISK
write.csv(x = dfFinal, file = "GBM_TUNING_PARAMETERS.csv", row.names = FALSE)
write.csv(x = dfImpVars, file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv", row.names = FALSE)
# Cleanup the environment and load libraries
rm(list = ls(all.names = TRUE))
library(h2o)
# Initialize H2O :: DELL_LAPTOP
h2o.init(nthreads = -1, min_mem_size = "6G")
# Initialize H2O :: LENOVO_AIO
#h2o.init(nthreads = -1, min_mem_size = "3500M")
# Read Train & Test into H2O - DELL_LAPTOP
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
# Read Train & Test into H2O - LENOVO_AIO
#AllStateTrain.hex = h2o.uploadFile(path = "D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
#AllStateTest.hex = h2o.uploadFile(path = "D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
# Transform "loss" variable to Log(loss)
AllStateTrain.hex$loss = h2o.log(AllStateTrain.hex$loss)
# No loss variable in AllStateTest.hex
# Save and remove id column from Train & Test dataset
TrainId = AllStateTrain.hex$id
TestId = AllStateTest.hex$id
AllStateTrain.hex$id = NULL
AllStateTest.hex$id = NULL
# Variable names
vFactors = paste0("cat", 1:116)
vNumbers = paste0("cont", 1:14)
# Perform PCA on numeric data >> Remove original attributes >> Select & attach important components
PCA = h2o.prcomp(training_frame = AllStateTrain.hex, x = vNumbers, k = length(vNumbers), model_id = "PCA_01", transform = "STANDARDIZE", seed = 1)
# Remove Continuous variable and add PCA Score - Train data frame
AllStateTrainPCA.hex = h2o.assign(data = h2o.predict(object = PCA, newdata = AllStateTrain.hex), key = "AllStateTrainPCA.hex")
AllStateTrain.hex[ ,vNumbers] = NULL
AllStateTrain.hex = h2o.cbind(AllStateTrain.hex, AllStateTrainPCA.hex[ ,1:12])
# Remove Continuous variable and add PCA Score - Test Data Frame
AllStateTestPCA.hex = h2o.assign(data = h2o.predict(object = PCA, newdata = AllStateTest.hex), key = "AllStateTestPCA.hex")
AllStateTest.hex[ ,vNumbers] = NULL
AllStateTest.hex = h2o.cbind(AllStateTest.hex, AllStateTestPCA.hex[ ,1:12])
# Split Training Data into Train & Validation set
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 1)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
# Attribute split for further modelling.
DepAttrib = "loss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
HyperParam = list(learn_rate = 0.02, ntrees = 2500, max_depth = c(7), learn_rate_annealing = c(0.999, 0.997, 0.995, 0.990, 0.980, 0.950, 0.900))
KaggleGrid5 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "GBM_GRID_LR_ANNEAL_1",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
## score every 5 trees to make early stopping reproducible
score_tree_interval = 5)
# LIST OF GRIDS FROM WHICH DATA NEEDS TO BE EXTRACTED
#GRID_Ids = c("GRID_LEARNRATE_NOANNEAL_2", "GRID_LEARNRATE_NOANNEAL_3", "GRID_LEARNRATE_NOANNEAL_4", "GRID_LEARNRATE_NOANNEAL_5", "GRID_LEARNRATE_NOANNEAL_6")
#GRID_Ids = c("KAGGLE_GRID_4")
#GRID_Ids = c("GBM_GRID_LR_ANNEAL_1", "KAGGLE_GRID_4")
GRID_Ids = c("GBM_GRID_LR_ANNEAL_1")
# EMPTY DATA FRAMES FOR CONSOLIDATING DATA
dfFinal = data.frame()
dfImpVars = data.frame()
for(i in 1:length(GRID_Ids))
{
# OBTAIN GRID AND "THE BEST" MODEL OF THAT GRID
GRID = h2o.getGrid(grid_id = GRID_Ids[i], sort_by = "mse")
TopMod = h2o.getModel(model_id = GRID@model_ids[[1]])
ModelName = unlist(GRID@model_ids)
# EXTRACT MODEL PARAMETERS FOR EACH MODEL IN THE GRID
ntrees = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$ntrees}))
max_depth = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$max_depth}))
learn_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate}))
learn_rate_annealing = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate_annealing}))
col_sample_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$col_sample_rate}))
stopping_rounds = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_rounds}))
stopping_metric = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_metric}))
stopping_tolerance = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_tolerance}))
score_tree_interval  = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$score_tree_interval}))
distribution = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$distribution}))
# EXTRACT IMPORTANT PARAMETERS FOR SCORING ROUND OF EACH MODEL IN THE GRID
Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_deviance"])}))
TrainDev_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_deviance[which.min(y@model$scoring_history[,"validation_deviance"])]}))
ntree_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_deviance"])]}))
Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_mae"])}))
TrainMAE_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_mae[which.min(y@model$scoring_history[,"validation_mae"])]}))
ntree_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_mae"])]}))
MaxTreesBuilt = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
# COMBINE EXTRACTED RESULTS VERTICALLY
df1 = cbind(ModelName, ntrees, max_depth, learn_rate, learn_rate_annealing, col_sample_rate, stopping_rounds, stopping_metric, stopping_tolerance,
score_tree_interval, distribution, Min_Val_Dev, TrainDev_At_Min_Val_Dev, ntree_At_Min_Val_Dev, Min_Val_MAE, TrainMAE_At_Min_Val_MAE,
ntree_At_Min_Val_MAE, MaxTreesBuilt)
# UPDATE FINAL DATA FRAMES: MODEL PARAMETERS + SCORING DATA + IMPORTANT VARIABLS
dfFinal = rbind(dfFinal, as.data.frame(df1))
dfImpVars = rbind(dfImpVars, TopMod@model$variable_importances)
}
# WRITE TO DISK
write.csv(x = dfFinal, file = "GBM_TUNING_PARAMETERS.csv", row.names = FALSE)
write.csv(x = dfImpVars, file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv", row.names = FALSE)
?h2o.gbm
KaggleGrid5
KaggleGrid = h2o.getGrid("GBM_GRID_LR_ANNEAL_1", sort_by = "mse")
KaggleGrid
KaggleGrid = h2o.getGrid("GBM_GRID_LR_ANNEAL_1", sort_by = "mse")
TopModel = h2o.getModel(model_id = KaggleGrid@model_ids[[1]])       # MAX_DEPTH = 8
# Generate Predictions
predGBM = h2o.predict(object = TopModel, newdata = AllStateTest.hex)
# Following step is required only for Log(loss) predictions
predGBM = h2o.exp(predGBM)
dfGBMPredictions = as.data.frame(h2o.cbind(TestId, predGBM))
names(dfGBMPredictions) = c("id", "loss")
write.csv(x = dfGBMPredictions, file = "H2O_GBM_01112016_03.csv", row.names = FALSE)
# Cleanup the environment and load libraries
rm(list = ls(all.names = TRUE))
library(h2o)
# Initialize H2O :: DELL_LAPTOP
h2o.init(nthreads = -1, min_mem_size = "7G")
# Initialize H2O :: LENOVO_AIO
#h2o.init(nthreads = -1, min_mem_size = "3500M")
# Read Train & Test into H2O - DELL_LAPTOP
AllStateTrain.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
AllStateTest.hex = h2o.uploadFile(path = "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
# Read Train & Test into H2O - LENOVO_AIO
#AllStateTrain.hex = h2o.uploadFile(path = "D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/train.csv", destination_frame = "AllStateTrain.hex", header = TRUE)
#AllStateTest.hex = h2o.uploadFile(path = "D:/10 CONTINUOUS LEARNING/83 KAGGLE/KAGGLE_COMPETITIONS/2016_01_AllState_Claim_Severity_Prediction/test.csv", destination_frame = "AllStateTest.hex", header = TRUE)
# Transform "loss" variable to Log(loss)
AllStateTrain.hex$loss = h2o.log(AllStateTrain.hex$loss)
# No loss variable in AllStateTest.hex
# Save and remove id column from Train & Test dataset
TrainId = AllStateTrain.hex$id
TestId = AllStateTest.hex$id
AllStateTrain.hex$id = NULL
AllStateTest.hex$id = NULL
# Variable names
vFactors = paste0("cat", 1:116)
vNumbers = paste0("cont", 1:14)
# Perform PCA on numeric data >> Remove original attributes >> Select & attach important components
PCA = h2o.prcomp(training_frame = AllStateTrain.hex, x = vNumbers, k = length(vNumbers), model_id = "PCA_01", transform = "STANDARDIZE", seed = 1)
# Remove Continuous variable and add PCA Score - Train data frame
AllStateTrainPCA.hex = h2o.assign(data = h2o.predict(object = PCA, newdata = AllStateTrain.hex), key = "AllStateTrainPCA.hex")
AllStateTrain.hex[ ,vNumbers] = NULL
AllStateTrain.hex = h2o.cbind(AllStateTrain.hex, AllStateTrainPCA.hex[ ,1:12])
# Remove Continuous variable and add PCA Score - Test Data Frame
AllStateTestPCA.hex = h2o.assign(data = h2o.predict(object = PCA, newdata = AllStateTest.hex), key = "AllStateTestPCA.hex")
AllStateTest.hex[ ,vNumbers] = NULL
AllStateTest.hex = h2o.cbind(AllStateTest.hex, AllStateTestPCA.hex[ ,1:12])
# Split Training Data into Train & Validation set
SplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 1)
ModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = "ModTrain.hex")
ModTest.hex = h2o.assign(data = SplitFrames[[2]], key = "ModTest.hex")
# Attribute split for further modelling.
DepAttrib = "loss"
IndAttrib = setdiff(names(ModTrain.hex), DepAttrib)
HyperParam = list(learn_rate = 0.03, ntrees = 1200, max_depth = c(4,5,6,7,8,9,10), learn_rate_annealing = c(1,0.999,0.998))
HyperParam
KaggleGrid6 <-       h2o.grid(algorithm = "gbm",
x = IndAttrib,
y = DepAttrib,
training_frame = ModTrain.hex,
grid_id = "GRID_LR_0_PT_03",
hyper_params = HyperParam,
validation_frame = ModTest.hex,
seed = 1,
distribution = "gaussian",
stopping_rounds = 5,
stopping_tolerance = 0.0001,
stopping_metric = "deviance",
## sample 80% of rows per tree
sample_rate = 0.8,
## sample 80% of columns per split
col_sample_rate = 0.8,
score_tree_interval = 5)
GRID_Ids = c("GRID_LR_0_PT_03")
# EMPTY DATA FRAMES FOR CONSOLIDATING DATA
dfFinal = data.frame()
dfImpVars = data.frame()
for(i in 1:length(GRID_Ids))
{
# OBTAIN GRID AND "THE BEST" MODEL OF THAT GRID
GRID = h2o.getGrid(grid_id = GRID_Ids[i], sort_by = "mse")
TopMod = h2o.getModel(model_id = GRID@model_ids[[1]])
ModelName = unlist(GRID@model_ids)
# EXTRACT MODEL PARAMETERS FOR EACH MODEL IN THE GRID
ntrees = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$ntrees}))
max_depth = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$max_depth}))
learn_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate}))
learn_rate_annealing = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$learn_rate_annealing}))
col_sample_rate = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$col_sample_rate}))
stopping_rounds = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_rounds}))
stopping_metric = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_metric}))
stopping_tolerance = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$stopping_tolerance}))
score_tree_interval  = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$score_tree_interval}))
distribution = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}), function(y){y@allparameters$distribution}))
# EXTRACT IMPORTANT PARAMETERS FOR SCORING ROUND OF EACH MODEL IN THE GRID
Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_deviance"])}))
TrainDev_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_deviance[which.min(y@model$scoring_history[,"validation_deviance"])]}))
ntree_At_Min_Val_Dev = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_deviance"])]}))
Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){min(y@model$scoring_history[,"validation_mae"])}))
TrainMAE_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$training_mae[which.min(y@model$scoring_history[,"validation_mae"])]}))
ntree_At_Min_Val_MAE = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){y@model$scoring_history$number_of_trees[which.min(y@model$scoring_history[,"validation_mae"])]}))
MaxTreesBuilt = unlist(lapply(lapply(GRID@model_ids, function(x){h2o.getModel(x)}),
function(y){max(y@model$scoring_history$number_of_trees)}))
# COMBINE EXTRACTED RESULTS VERTICALLY
df1 = cbind(ModelName, ntrees, max_depth, learn_rate, learn_rate_annealing, col_sample_rate, stopping_rounds, stopping_metric, stopping_tolerance,
score_tree_interval, distribution, Min_Val_Dev, TrainDev_At_Min_Val_Dev, ntree_At_Min_Val_Dev, Min_Val_MAE, TrainMAE_At_Min_Val_MAE,
ntree_At_Min_Val_MAE, MaxTreesBuilt)
# UPDATE FINAL DATA FRAMES: MODEL PARAMETERS + SCORING DATA + IMPORTANT VARIABLS
dfFinal = rbind(dfFinal, as.data.frame(df1))
dfImpVars = rbind(dfImpVars, TopMod@model$variable_importances)
}
# WRITE TO DISK
write.csv(x = dfFinal, file = "GBM_TUNING_PARAMETERS.csv", row.names = FALSE)
write.csv(x = dfImpVars, file = "GBM_TOP_MODEL_VARIABLE_IMPORTANCE.csv", row.names = FALSE)
KaggleGrid = h2o.getGrid("GRID_LR_0_PT_03", sort_by = "mse")
TopModel = h2o.getModel(model_id = KaggleGrid@model_ids[[1]])       # MAX_DEPTH = 8
TopModel
KaggleGrid = h2o.getGrid("GRID_LR_0_PT_03", sort_by = "mse")
TopModel = h2o.getModel(model_id = KaggleGrid@model_ids[[1]])       # MAX_DEPTH = 8
# Generate Predictions
predGBM = h2o.predict(object = TopModel, newdata = AllStateTest.hex)
# Following step is required only for Log(loss) predictions
predGBM = h2o.exp(predGBM)
dfGBMPredictions = as.data.frame(h2o.cbind(TestId, predGBM))
names(dfGBMPredictions) = c("id", "loss")
write.csv(x = dfGBMPredictions, file = "H2O_GBM_02112016_01.csv", row.names = FALSE)
