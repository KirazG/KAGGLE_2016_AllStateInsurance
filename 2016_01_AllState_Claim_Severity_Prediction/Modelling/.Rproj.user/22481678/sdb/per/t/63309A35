{
    "collab_server" : "",
    "contents" : "##### EXPERIMENT WITH KAGGLE DATA SET MODELLING\n\n##### FEATURE ENGINEERING: NONE\n##### FRAMEWORK: H2O\n\nrm(list = ls(all.names = TRUE))\nlibrary(h2o)\n\n# Initialize H2O\nh2o.init(nthreads = -1, max_mem_size = \"1G\")\n\n# Cleanup H2O Enviroment\n#h2o.removeAll()\n\n# Read Train & Test into H2O\nAllStateTrain.hex = h2o.uploadFile(path = \"C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/train.csv\", destination_frame = \"AllStateTrain.hex\", header = TRUE)\nAllStateTest.hex = h2o.uploadFile(path = \"C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/test.csv\", destination_frame = \"AllStateTest.hex\", header = TRUE)\n\nAllStateTrain.hex$id = NULL\n\n# DATA TRANSFORMATION: Converting Loss varibale into Log10(loss) to make the Right Skewed distribution Normal\nncol(AllStateTrain.hex)\nAllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss >= 1, ]\nAllStateTrain.hex$LogLoss = h2o.log(AllStateTrain.hex$loss)\nncol(AllStateTrain.hex)\n# Selecting Only Subset of Training Data - Potentially Exlcuding Outliers\n\n#nrow(AllStateTrain.hex)\n#AllStateTrain.hex = AllStateTrain.hex[AllStateTrain.hex$loss <= 52000, ]\n#nrow(AllStateTrain.hex)\n\nSplitFrames = h2o.splitFrame(data = AllStateTrain.hex, ratios = 0.7, seed = 2016)\nModTrain.hex = h2o.assign(data = SplitFrames[[1]], key = \"ModTrain.hex\")\nModTest.hex = h2o.assign(data = SplitFrames[[2]], key = \"ModTest.hex\")\n\n# DepAttrib = \"loss\"\nDepAttrib = \"LogLoss\"\nIndAttrib = setdiff(names(ModTrain.hex), DepAttrib)\n# Using Only Top 23 attributes selected from DRF [This was run on 13-10-2016]\n#IndAttrib = c(\"cat116\",\"cat80\",\"cat79\",\"cat112\",\"cat113\",\"cat101\",\"cat87\",\"cat100\",\"cat57\",\"cat110\",\"cat115\",\"cont2\",\"cat12\",\"cat81\",\"cont7\",\"cat105\",\"cat114\",\"cat107\",\"cat103\",\"cont12\",\"cat104\",\"cat111\",\"cat106\")\n\n################################################################################\n##### GLM with Lasso (L1), Ridge (L2) & ElasticNet @ Alpha = 0.5           #####\n################################################################################\n\nglmRidge = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = \"AllState_Ridge_01\", family = \"gaussian\", alpha = 0, lambda_search = TRUE, validation_frame = ModTest.hex)\n\nglmENet = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = \"AllState_ElasticNet_01\", family = \"gaussian\", alpha = 0.5, lambda_search = TRUE, validation_frame = ModTest.hex)\n\nglmLasso = h2o.glm(x = IndAttrib, y = DepAttrib, training_frame = ModTrain.hex, model_id = \"AllState_Lasso_01\", family = \"gaussian\", alpha = 1, lambda_search = TRUE, validation_frame = ModTest.hex)\n\n### MAE calculation\nh2o.mae(object = glmRidge, train = TRUE, valid = TRUE)\nh2o.mae(object = glmENet, train = TRUE, valid = TRUE)\nh2o.mae(object = glmLasso, train = TRUE, valid = TRUE)\n\n### Generate Predictions\n#predRidge = h2o.predict(object = glmRidge, newdata = AllStateTest.hex)\n#predENet = h2o.predict(object = glmENet, newdata = AllStateTest.hex)\n#predLasso = h2o.predict(object = glmLasso, newdata = AllStateTest.hex)\n\npredRidge = h2o.predict(object = glmRidge, newdata = ModTest.hex)\npredENet = h2o.predict(object = glmENet, newdata = ModTest.hex)\npredLasso = h2o.predict(object = glmLasso, newdata = ModTest.hex)\n\nCALC_MAE(ModTest.hex$loss, predRidge)\nCALC_MAE(ModTest.hex$loss, predENet)\nCALC_MAE(ModTest.hex$loss, predLasso)\n\nsum(predRidge - predENet)\nsum(predRidge - predLasso)\n\n### Convert all predictions to R DataFrames\n\ndfRidge = as.data.frame(h2o.cbind(AllStateTest.hex$id, predRidge))\nnames(dfRidge) = c(\"id\", \"loss\")\n\ndfEnet = as.data.frame(h2o.cbind(AllStateTest.hex$id, predENet))\nnames(dfEnet) = c(\"id\", \"loss\")\n\ndfLasso = as.data.frame(h2o.cbind(AllStateTest.hex$id, predLasso))\nnames(dfLasso) = c(\"id\", \"loss\")\n\n### Write all predictions into a CSV\nwrite.csv(x = dfRidge, file = \"../Predictions/2016_10_13/H2O_Ridge.csv\", row.names = FALSE)\nwrite.csv(x = dfEnet, file = \"../Predictions/2016_10_13/H2O_Enet.csv\", row.names = FALSE)\nwrite.csv(x = dfLasso, file = \"../Predictions/2016_10_13/H2O_Lasso.csv\", row.names = FALSE)\n\n\n################################################################################\n##### Grid Search for the best GLM - with all variables                    #####\n################################################################################\n\n### Allowing Lasso & Ridge Regualarization To Be Included In GRID SEARCH\n\nlamdas = c(10,1,0.1,0.01,0.001,0.0001,0.00001,0.000001,0.0000001)\nAlpha = seq(0,1,0.1)\nHParam = list(alpha = Alpha, lambda = lamdas)\n\nglmGridSearch = h2o.grid(algorithm = \"glm\", \n                         grid_id = \"GLMGrid_01\", \n                         hyper_params = HParam, \n                         x = IndAttrib,\n                         y = DepAttrib,\n                         training_frame = ModTrain.hex,\n                         family = \"gaussian\",\n                         is_supervised = TRUE)\n\nglmGridModels = lapply(glmGridSearch@model_ids, function(x){h2o.getModel(x)})\nMAE = unlist(lapply(glmGridModels, function(x) { h2o.mae(object = x)}))\nBestGridModel = glmGridModels[[which.min(MAE)]]\n\n### Generate Predictions From The Best Grid Model & Write To CSV\npredGridGLM = h2o.predict(object = BestGridModel, newdata = AllStateTest.hex)\ndfGridGLM = as.data.frame(h2o.cbind(AllStateTest.hex$id, predGridGLM))\nnames(dfGridGLM) = c(\"id\", \"loss\")\nwrite.csv(x = dfGridGLM, file = \"H2O_GridGLM.csv\", row.names = FALSE)\n\n\n### NOT allowing Lasso & Ridge Regualarization To Be Included In GRID SEARCH\n### Narrowed down the values for \"lambdas\" and expanded the values for Alpha\n\nLamdas = c(0.001,0.0001,0.00001,0.000001,0.0000001,0.00000001,0.000000001)\nAlpha = seq(0.5,0.95,0.05)\nHParam = list(alpha = Alpha, lambda = Lamdas)\n\nglmGridSearch2 = h2o.grid(algorithm = \"glm\", \n                         grid_id = \"GLMGrid_02\", \n                         hyper_params = HParam, \n                         x = IndAttrib,\n                         y = DepAttrib,\n                         training_frame = ModTrain.hex,\n                         validation_frame = ModTest.hex,\n                         family = \"gaussian\",\n                         is_supervised = TRUE)\n\nglmGridModels2 = lapply(glmGridSearch2@model_ids, function(x){h2o.getModel(x)})\nMAE2 = unlist(lapply(glmGridModels2, function(x) {h2o.mae(object = x)}))\nBestGridModel2 = glmGridModels2[[which.min(MAE2)]]\n\n### Generate Predictions From The Best Grid Model & Write To CSV\npredGridGLM2 = h2o.predict(object = BestGridModel2, newdata = AllStateTest.hex)\ndfGridGLM2 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predGridGLM2))\nnames(dfGridGLM2) = c(\"id\", \"loss\")\nwrite.csv(x = dfGridGLM2, file = \"H2O_GridGLM_2.csv\", row.names = FALSE)\n\n\n################################################################################\n#### Trying Cross Validation with Lasso Regression                         #####\n################################################################################\n\nglmLasso2 = h2o.glm(x = IndAttrib, \n                    y = DepAttrib, \n                    training_frame = AllStateTrain.hex, \n                    model_id = \"AllState_Lasso_02\", \n                    family = \"gaussian\", alpha = 1, \n                    nfolds = 10)\n\nh2o.mae(object = glmLasso2, train = TRUE)\n\n\n#### GBM Model: BASIC GBM MODEL - BEST ACCURACY SO FAR (MODEL DIRECTLY CREATED IN H2O FLOW)\n\nGBM1 <- h2o.getModel(model_id = \"gbm-627f0100-b75d-497a-943b-59227d449492\")\nh2o.mae(object = GBM1)\n### Generate Predictions From The Best Grid Model & Write To CSV\npredGBM1 = h2o.predict(object = GBM1, newdata = AllStateTest.hex)\ndfGBM1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predGBM1))\nnames(dfGBM1) = c(\"id\", \"loss\")\nwrite.csv(x = dfGBM1, file = \"H2O_GBM1.csv\", row.names = FALSE)\n\n\n################################################################################\n##### DISTRIBUTED RANDOM FOREST WITH H20                                   #####\n################################################################################\n\n##### GRID SEARCH MODEL_01: 80-100 Min of Grid Search\n\n#HypParams = list(ntrees = c(50,75,100), max_depth = c(18,20,22))\nHypParams = list(ntrees = c(100,125), max_depth = c(20))\n\ndrfGridSearch1 = h2o.grid(algorithm = \"randomForest\", \n                          grid_id = \"DRF_GRID_01\", \n                          hyper_params = HypParams, \n                          x = IndAttrib,\n                          y = DepAttrib,\n                          training_frame = ModTrain.hex,\n                          validation_frame = ModTest.hex,\n                          col_sample_rate_per_tree = 0.5,\n                          is_supervised = TRUE,\n                          seed = 2016)\n\n# BEST MODEL: ntree = 100 | max_depth = 22 | seed = 100 | features = ALL\ndrfGrid1 <- h2o.getGrid(grid_id = \"DRF_GRID_01\", sort_by = \"mse\", decreasing = FALSE)\nprint(drfGrid1)\ndrfBestGridModel1 <- h2o.getModel(drfGrid1@model_ids[[1]])\nh2o.mae(object = drfBestGridModel1, train = TRUE, valid = TRUE)\n\n# Generate Predictions\npredDRF1 = h2o.predict(object = drfBestGridModel1, newdata = AllStateTest.hex)\ndfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))\nnames(dfDRF1) = c(\"id\", \"loss\")\nwrite.csv(x = dfDRF1, file = \"H2O_DRF_01.csv\", row.names = FALSE)\n\n### Selecting important attribites from the best DRF model [ScaledImportance > 5%]\nimpVar = h2o.varimp(drfBestGridModel1)\nimpAttribs = impVar[impVar$scaled_importance >= 0.05,]$variable\n\n# Rebuilding the DRF with only important attributes - No Cross Validation\ndrfModel1 <- h2o.randomForest(x = impAttribs,\n                              y = DepAttrib,\n                              training_frame = ModTrain.hex, \n                              model_id = \"DRF_MODEL_01\", \n                              validation_frame = ModTest.hex, \n                              ntrees = 100, \n                              max_depth = 22, \n                              seed = 2016)\n\nh2o.mae(object = drfModel1, train = TRUE, valid = TRUE)\nh2o.varimp_plot(model = drfModel1)\n\n# Generate Predictions\npredDRF1 = h2o.predict(object = drfModel1, newdata = AllStateTest.hex)\ndfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))\nnames(dfDRF1) = c(\"id\", \"loss\")\nwrite.csv(x = dfDRF1, file = \"H2O_DRF_02.csv\", row.names = FALSE)\n\n##### DRF with only important attributes: 10-fold Cross Validation\n# COULD NOT USE\ndrfModel2 <- h2o.randomForest(x = impAttribs, y = DepAttrib, training_frame = AllStateTrain.hex, model_id = \"DRF_MODEL_02\", ntrees = 50, max_depth = 20, seed = 2016, nfolds = 10, stopping_rounds = 2, stopping_metric = \"MSE\", stopping_tolerance = 1e-3, score_tree_interval = 50)\n\nh2o.mae(object = drfModel2, train = TRUE)\n\n\n##### GBM\n\nGBM2 <- h2o.gbm(x = impAttribs, \n                y = DepAttrib, \n                training_frame = ModTrain.hex, \n                model_id = \"GBM_MODEL_02\", \n                validation_frame = ModTest.hex, \n                ntrees = 350, \n                seed = 2016, \n                distribution = \"gaussian\", \n                max_depth = 5, \n                stopping_rounds = 3, \n                stopping_metric = \"MSE\")\n\nh2o.mae(object = GBM2, train = TRUE, valid = TRUE)\nh2o.varimp_plot(model = GBM2)\n\n# Generate Predictions\npredDRF1 = h2o.predict(object = GBM2, newdata = AllStateTest.hex)\ndfDRF1 = as.data.frame(h2o.cbind(AllStateTest.hex$id, predDRF1))\nnames(dfDRF1) = c(\"id\", \"loss\")\nwrite.csv(x = dfDRF1, file = \"H2O_GBM_04.csv\", row.names = FALSE)\n\n\n\n\n\nCALC_MAE <- function(Actuals, Predicted)\n{\n    ifelse((length(Actuals) != 0 & length(Predicted) != 0 & (length(Actuals) == length(Predicted))), return(sum(abs(Actuals - Predicted))/nrow(Actuals)), return(NaN))\n}",
    "created" : 1476429934555.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3539707783",
    "id" : "63309A35",
    "lastKnownWriteTime" : 1476438062,
    "last_content_update" : -2147483648,
    "path" : "C:/02 KAGGLE/2016_AllState_Claim_Severity_Prediction/Modelling/AllStateInsurance_Modelling_GLM_01.R",
    "project_path" : "AllStateInsurance_Modelling_GLM_01.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}